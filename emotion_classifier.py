# -*- coding: utf-8 -*-
"""Emotion classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y4tnxuYz-HQ68RNHtotIvm409MuGEw1c

# **LOADING DATASET**
"""

import pandas as pd
pd.read_csv("emotions.csv")

df = pd.read_csv("emotions.csv")

print(df.head())

print(df.info())

import pandas as pd
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

nltk.download('stopwords')

print(df['label'].value_counts())

"""# **Mapping label integers to emotions**"""

label_map = {
    0: 'sadness',
    1: 'joy',
    2: 'love',
    3: 'anger',
    4: 'fear',
    5: 'surprise'
}
df['emotion'] = df['label'].map(label_map)

stop_words = set(stopwords.words('english'))

def preprocess(text):
    text = re.sub(r"http\S+", "", text)
    text = re.sub(r"[^a-zA-Z\s]", "", text)
    text = text.lower()
    tokens = text.split()
    tokens = [word for word in tokens if word not in stop_words]
    return " ".join(tokens)

df['clean_text'] = df['text'].apply(preprocess)

vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(df['clean_text'])

le = LabelEncoder()
y = le.fit_transform(df['emotion'])

import numpy as np
unique, counts = np.unique(y, return_counts=True)
for label, count in zip(unique, counts):
    print(f"Label {label} ({le.classes_[label]}): {count} samples")

"""# **label encoding and vectorization**

"""

df_filtered = df.copy()
emotion_counts = df_filtered['emotion'].value_counts()

valid_emotions = emotion_counts[emotion_counts >= 2].index
df_filtered = df_filtered[df_filtered['emotion'].isin(valid_emotions)]

y = le.fit_transform(df_filtered['emotion'])
X = vectorizer.fit_transform(df_filtered['clean_text'])

"""# **Training and testing**"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

"""# **Accuracy and classification report of Linear SVC**

"""

from sklearn.svm import LinearSVC

model = LinearSVC()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)


from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
print(classification_report(y_test, y_pred, target_names=le.classes_))

import matplotlib.pyplot as plt
import seaborn as sns

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.title("Confusion Matrix (LinearSVC)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""# **Example input and predicting of Linear SVC**

"""

test_sentence ="He was afraid of the dark."

X_input = vectorizer.transform([test_sentence])


predicted_label = model.predict(X_input)

emotion = le.inverse_transform(predicted_label)

print(" Predicted Emotion:", emotion[0])

import joblib

# Save the model
joblib.dump(model, "linear_svc_model.pkl")

# Later, load the model
# model = joblib.load("linear_svc_model.pkl")